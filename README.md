This repository includes R scripts and data for the paper, No Frills: Simple Regularities go a Long Way in the Development of Word Knowledge. 

This project was inspired by the fact that AI langauge models have achieved impressive success in emulating human langauge fluency, even when trained on relatively small amounts of everyday language input to children. 

These successes raise the possibility that children pick up similar kinds of information from everyday language as AI language models. Yet, there is evidence to suggest that children do not possess learning mechanisms that are as sophisticated as those implemented in today's AI language models. Therefore, this project examined whether children might pick up on simpler information from their everyday language experiences.

The steps involved in this project were to process datasets (corpora) of transcribed child language input, derive measures of the information available in the input that children might be able to learn, and test whether these measures can predict child langauge learning.

This repository includes components with scripts and data for the following steps. To reproduce the analyses, it is recommended that you run the corpus processing (step 1) and deriving measures (step 2) steps before the others:

(1) Corpus processing

(2) Deriving measures of information available in language (co-occurrence)

(3) Study 1: test whether the derived measures can support the acquisition of interconnected word knowledge (e.g., knowledge that "jump", "run" and "skip" are similar in meaning)

(4) Study 2: test whether the derived measures can predict the interconnected word knowledge that is acquired in infancy

(5) Study 3: test whether the derived measures can predict the interconnected word knowledge that is acquired across childhood
